---
layout: post
title: Weekly Report - 2018-06-04 to 2018-06-08
---

### Introduction: MaxEnt as a Final State Machine

Last week my concentration was devoted to the coding of the package into a fully fleshed model handler. This turned into several conditions to be met by the code towards scientific maintainability, also in connection with my own thesis work. Following on emerging principles of [Research Software Engineering](https://openresearchsoftware.metajnl.com/articles/10.5334/jors.184/), we wish this code to be extensible, reflect design rather than pure craftsmanship and be extensively productive. MaxEnt is a useful type of model, yet existing implementations concentrate on its outcomes rather on the processes. We pretend to turn this statement on its heels.

In order to perform the latter, we need to ensure that users will proceed in consisten steps, or otherwise, that warnings and errors will be logged and printed correspondingly. Essentially, users should be concerned with the scientific workflow instead of the software development workflow, and that requires bounding the set of acceptable sequences of operations as represented by method calls. Formally, this is a [Mealy finite state machine](https://en.wikipedia.org/wiki/Mealy_machine). One way to achieve the latter is defining possible states the machine is in

```python
class ModelState(IntEnum):
    EMPTY = 1,
    INITIALIZED = 2,
    LOADED_NOENV = 3,
    LOADED_FULL = 4,
    COMPUTED = 5
```

and, whenever an operation is performed, we would like to make sure that the machine model takes care under the hood of all operations. For every method call, there are pre- and post-conditions that need to be met. If preconditions are not entirely met but they leave the system in a runnable condition, warnings should be issued and execution continued. Errors are issues that would prevent the internal state from being consistent. We achive this with *guard* operations. Guards are function calls that take care of pre- and post-conditions and can halt the execution of the method call if needed. We record each type of operation to have code that takes care of its effects:

```python
class ModelOperation(Enum):
    CREATEMODEL = "Create a new model",
    DESCRIBEEXP = "Describe experiment",
    SETINPUTFILES = "Set input files",
    SETOUTPUTFILES = "Set output files",
    SETGEOPARAMS= "Set geographic parameters",
    SETGEOBOUNDS = "Set geographic bounds",
    PARAMSTOJSON = "Load parameters to JSON file",
    LOGTOCVS = "Save log to CSV file",
    LOGFROMCVS = "Load log from CSV file",
    CONSUMEDATAENV = "Consuming background  environmental data",
    CONSUMEDATAFTR = "Consuming festures data",
    CONSUMEDATAPO = "Consuming presence-only data",
    CONSUMEALL = "Consuming all data for the model",
    MAKEGRID = "Creating the grid with PO data",
    COMPUTE = "Compute the model",
    RECOMPUTE = "Recompute the model",
    DIFF = "Differential analysis against model",
    COPY = "Copting the model into a new fork"
```

We then use the type of machine operation to signal the start and end of pre/post-conditions, for instance, to setup input files

```python
def setinputfiles(self, csvenvf, csvenvd, csvpodt):
    self.assertstate(ModelOperation.SETINPUTFILES)

    self.__jsonconfig['input']['envfeatures'] = csvenvf
    self.__jsonconfig['input']['envdata'] = csvenvd
    self.__jsonconfig['input']['podata'] = csvpodt

    self.refreshstate(ModelOperation.SETINPUTFILES)

```

The guard **assertstate** ensures that the state is in a proper condition to execute all statements that follow. The guard **refreshstate** performs housekeeping and ensures a consistent state for the next method to be called.

### MaxEnt experiments: a JSON representation

Experiments should be annotated and replicable. Our models aim at being fully packageable and storable. Packaging includes saving the machine state, the log and all data into a compressed file format. Storing the experiment implies saving all parameters without necessarily loading data. This ensures portability and changeability. For the present, these is the current state of what is stored in the innermost JSON representation of parameters:

```python
self.__jsonconfig['experiment']['shortname'] = ''
self.__jsonconfig['experiment']['description'] = ''
self.__jsonconfig['experiment']['author'] = ''
self.__jsonconfig['experiment']['email'] = ''
self.__jsonconfig['experiment']['organization'] = ''
self.__jsonconfig['experiment']['date'] = ''
self.__jsonconfig['experiment']['version'] = ''
self.__jsonconfig['input']['envfeatures'] = ''
self.__jsonconfig['input']['envdata'] = ''
self.__jsonconfig['input']['podata'] = ''
self.__jsonconfig['geographic']['needsref'] = False
self.__jsonconfig['geographic']['reffile'] = ''
self.__jsonconfig['geographic']['datum'] = 'EPSG:4326'
self.__jsonconfig['geographic']['datumfilter'] = DarwinCoreSemantics.DATUM
self.__jsonconfig['geographic']['latfilter'] = DarwinCoreSemantics.LAT
self.__jsonconfig['geographic']['lonfilter'] = DarwinCoreSemantics.LON
self.__jsonconfig['geographic']['decimation'] = 1
self.__jsonconfig['geographic']['lowerleft'] = (0.0, 0.0)
self.__jsonconfig['geographic']['upperright'] = (0.0, 0.0)
self.__jsonconfig['geographic']['distance'] = 0
self.__jsonconfig['output']['cvs'] = ''
self.__jsonconfig['output']['png'] = ''
self.__jsonconfig['output']['kml'] = ''
self.__jsonconfig['output']['log'] = ''
```

### The software interface

Up to this point, we can write our first simulation driver to compare a full model with a PO data-only model. Note that the language describes features of the experiment rather than of the computation.

```python
# Create a new model
mymodel = model.MaxEntModel()

# Describe the model
mymodel.describeexperiment("magnolias", "A test for MaxEnt",
                           "Santiago Nunez-Corrales", "nunezco2@illinois,edu",
                           "UIUC/NCSA/iSchool", "2018-06-22", "0.1")

# Set the input and output files
mymodel.setinputfiles("features_test.csv", "env_test.csv", "weakley2015.test")
mymodel.setoutputfiles("magnolia.csv", "magnolia.png", "magnolia.kml", "magnolia.log")
mymodel.setgeoparams(True, "counties_curated.csv")

# Consume the data
mymodel.consume()

# Run the model
mymodel.compute()

# Maybe, we want to remove all references to the environment in a new model and recompute it
# We would like to preserve the log. Carbon copies can be made in any moment.
mynewmodel =  mymodel.carboncopy()

# Roughly, 0.01 degrees corresponds to 1km
mynewmodel.setinputfiles("", "", "weakley2015.test")
mynewmodel.setgeobounds((30.91, -94.94), (39.78, -76.36), 0.01)
mynewmodel.recompute()

# Compare against the previous model
mydiff = mynewmodel.diff(mymodel)

# Show the comparison in a KML
mydiff.representKML()

# See the history of operations and outcomes that we have obtained through the logs
print mymodel.transcript
print mynewmodel.transcript

# Finally, save the machine state representation to a file
mymodel.paramstojson()

# And package the model appropriately
mymodel.package()

```

### Next steps

A main element to add is parametrization of the mathematical model, which will be performed along next week including introspection. The machine driver needs to be finished the upcoming week to cover all corner use cases and tested on the Whole Tale environment with observations gathered by Jessica. Moreover, our plan is to study the Magnolia dataset suggested by Nico. The main challenge is to find relevant environmental data associated to literature. The latter is not common.
