---
layout: post
title: Weekly Report - 2018-06-04 to 2018-06-08
---

### Introduction: implementation of MaxEnt for The Whole Tale in Python

Having performed the main design last week for an introspective version of MaxEnt and created the repository, this weel proceeded by cleaning the preliminary code and implementing functions around an algorithmic MaxEnt code. The first intuitions were as follows:

1. The original MaxEnt code may help verify the correctness of the code by exploring the original ideas in Java.
2. Replicating the original 2006 paper yields information about how the code proceeds.
3. A set of differential experiments then can be performed to evaluate how well the code works in an additional problem.

After the first images were produced, there were some differences with respect to the original paper, using the same parameters and methods. **Why?**

Possible causes were identified:

1. Our code does not follow the MaxEnt paper. This is being carefully checked against the original description and subsequent critiques in further literature.

2. Data were different. No. Same observation data for the two species (actually, a standard library example in scikit) and 

3. The differences are related to numerical factors. It is possible, since numpy uses 64-bit representations and controls for numerical error on small values, but the Java implementation does not.

4. Sorting of samples. The model of randomness in the Java version uses an *ad hoc* way for generating permutations, which may result in large differences due to poor permutation choice.

### On checking geographically bound complex simulation codes

The first step that ensued was revising the mathematics in the original MaxEnt code. One of the striking features of a functionally-well realized piece of code is the poor separation of concerns with respect to how the algorithmic segments and the display segments are mixed in MaxEnt. In principle, the design strategy (which made sense back in 2006 before accessible numerical libraries existed) was to build everything from scratch.

The main item on the intellectual queue is this: given the visual complexity of the output, as well as the semantic complexity, how can geographic codes be tested? The complexity, contrary to other scientific packages, does not depend on the difficulty of the iterative methods, or on complex equations but on the input data and how it relates to the output bit by bit. Testing geography in a relevant way is tricky.

At present, I have decided to slowly push code only after unit cases have passed. Two files have made it since yesterday. More will come during the weekend.

### A preliminary solution: small patch experiments

A method under design is via small patch experiments. A small patch experiment is a type of computational test that 

1. Can be easily tested and studed due to its small areas
2. It can be subject to checks of scaling laws
3. They are small enough to be synthetic
4. Features can covary and match plausible cases

In this case, a small experiment is a grid of less than 100x100 background features (pixels) where presence-only data can be overlayed.




